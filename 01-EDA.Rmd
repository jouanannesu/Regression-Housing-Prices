---
title: "05222022_EDA"
output: pdf_document
---

# Load packages 

```{r}
library(tidyverse) # data manipulation 
library(ggplot2)   # plotting
```

# Load data 

```{r}
data <- read.csv("train.csv")
```

# View data

```{r}
data %>% glimpse 
```

# Check data

```{r}
data %>% dim
```

# Data cleaning 

```{r}
# Count missing data
data_missing <- data %>%
  select(everything()) %>% 
  summarise_all(funs(sum(is.na(.))))
data_missing
```

```{r}
# # Remove Alley 
# data_clean <- data %>% select(-c(Alley)) %>% head
# data_clean %>% dim # Odd 
```

## EDA 

### Check SalePrice (response variable)
```{r}
# Compute summary statistics 
data %>% select(SalePrice) %>% summary()
```

```{r}
# Check 25, 75 quantile, potential outliers and normality 
data %>% ggplot(aes(x = SalePrice)) + geom_boxplot()

```

```{r}
# Flip the plot 
data %>% ggplot(aes(x = SalePrice)) + geom_boxplot() + coord_flip()
```

There may be outliers in the data set. 

### Remove the outliers 

```{r}
# Identify quantile values
quantile(data$SalePrice, prob = c(0.25, 0.75))
```

```{r}
# Identify observations 
row <- which(data$SalePrice < 129975 | data$SalePrice > 214000)
length(row)
```

We may have remove too many observations but let's come back to fix it later. 

```{r}
length(data$SalePrice)
```

```{r}
# Subset data
data_sub <- data[-c(row), ]
data_sub %>% dim
```

```{r}
# Replot to see if it's better
data_sub %>% ggplot(aes(x = SalePrice)) + geom_boxplot() 
```

Look better but may not be correct. 

### Check other predictor variables

Use bar plot for categorical variables. 

```{r}
data_sub %>% ggplot(aes(x = factor(MSZoning))) + geom_bar()
```

```{r}
# Add SalePrice
data_sub %>% ggplot(aes(x = factor(MSZoning), y = SalePrice)) + 
  geom_boxplot()
```

```{r}
data_sub %>% ggplot(aes(x = factor(OverallQual))) + geom_bar()
```

```{r}
data_sub %>% ggplot(aes(x = factor(OverallCond))) + geom_bar()
```

Probably better to write a function. 

```{r}
data_sub %>% ggplot(aes(x = TotalBsmtSF)) + geom_boxplot()
```

```{r}
# Add SalePrice
data_sub %>% ggplot(aes(x = TotalBsmtSF, y = SalePrice)) + geom_point() +
  geom_smooth(method='lm') # Overlay a regression line 
```

This implies that the model is a poor fit 
$$
\mu(SalePrice | TotalBsmtSF) = \beta_0 + \beta_1 TotalBsmtSF
$$

### Separate categorical variable from continuous variable 

```{r}
#rapply(data_sub, class = "numeric", f = levels, how = "list") # Not quite
```

```{r}
#rapply(data_sub, class = "factor", f = levels, how = "list")
```

The list goes on... 

```{r}
data_sub %>% glimpse
```


## Models 

Review SLR 

### SLR 

```{r}
fit1 <- lm(SalePrice ~ TotalBsmtSF, data = data_sub)
summary(fit1)
```

The model is given as
$$
\mu(SalePrice | TotalBsmtSF) = \beta_0 + \beta_1 TotalBsmtSF
$$

The fitted model is
$$
\hat{\mu}(SalePrice | TotalBsmtSF) = \hat{\beta_0} + \hat{\beta_1} TotalBsmtSF
$$
$$
= 1.522e05 + 1.257e01 * TotalBsmtSF
$$

The model is a poor fit (Adjusted R-squared: 0.03806). 

How about model assumption? One of the model assumptions is constant or equal variance, which is violated. Other assumptions include normality, independence, and linearlity. 

```{r}
library(broom)
fit1_df <- augment(fit1)
fit1_df %>% ggplot(aes(x = .fitted, y = .resid)) + geom_point() + 
  geom_hline(yintercept = 0) + 
  labs(title = "Residuals vs Fitted")
```

### MLR 

```{r}
fit2 <- lm(SalePrice ~ TotalBsmtSF + LotArea, data = data_sub)
summary(fit2)
```

The fitted model is
$$
\hat{\mu}(SalePrice | TotalBsmtSF) = \hat{\beta_0} + \hat{\beta_1} TotalBsmtSF + \hat{\beta_2} LotArea 
$$

The fit is till pretty poor. 

```{r}
fit2_df <- augment(fit2)
fit2_df %>% ggplot(aes(x = .fitted, y = .resid)) + geom_point() + 
  geom_hline(yintercept = 0) + 
  labs(title = "Residuals vs Fitted")
```

Fit 3 Add another continuous variable and see if R-squared or Adjusted R-squared changes.

Fit 4 Add another continuous variable.

Fit 5 Add another continuous variable. 

Fit 6 Return to fit1 but add an additional categorical variable. 




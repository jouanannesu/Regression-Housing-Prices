---
title: "05222022_EDA"
output: pdf_document
---

# Load packages 

```{r}
library(tidyverse) # data manipulation 
library(ggplot2)   # plotting
```

# Load data 

```{r}
data <- read.csv("train.csv")
```

# View data

```{r}
data %>% glimpse 
```

# Check data

```{r}
data %>% dim
```

# Data cleaning 

```{r}
# Count missing data
data_missing <- data %>%
  select(everything()) %>% 
  summarise_all(funs(sum(is.na(.))))
data_missing
```

```{r}
# colSums(is.na(data)) # base R
```

```{r}
# # Remove Alley 
# data_clean <- data %>% select(-c(Alley)) %>% head
# data_clean %>% dim # Odd 
```

We can consider replace NAs with mean values.

## EDA 

### Check SalePrice (response variable)
```{r}
# Compute summary statistics 
data %>% select(SalePrice) %>% summary()
```

```{r}
# Check 25, 75 quantile, potential outliers and normality 
data %>% ggplot(aes(x = SalePrice)) + geom_boxplot()
```

```{r}
# Flip the plot 
data %>% ggplot(aes(x = SalePrice)) + geom_boxplot() + coord_flip()
```

There may be outliers in the data set. 

### Remove the outliers 

```{r}
# Identify quantile values
quantile(data$SalePrice, prob = c(0.25, 0.75))
```

```{r}
# Identify observations 
row <- which(data$SalePrice < 129975 | data$SalePrice > 214000)
length(row)
```

We may have remove too many observations but let's come back to fix it later. 

```{r}
length(data$SalePrice)
```

```{r}
# Subset data
data_sub <- data[-c(row), ]
data_sub %>% dim
```

```{r}
# Replot to see if it's better
data_sub %>% ggplot(aes(x = SalePrice)) + geom_boxplot() 
```

Look better but may not be correct. 

### Check other predictor variables

Use bar plot for categorical variables. 

```{r}
data_sub %>% ggplot(aes(x = factor(MSZoning))) + geom_bar()
```

```{r}
# Add SalePrice
data_sub %>% ggplot(aes(x = factor(MSZoning), y = SalePrice)) + 
  geom_boxplot()
```

```{r}
data_sub %>% ggplot(aes(x = factor(OverallQual))) + geom_bar()
```

```{r}
data_sub %>% ggplot(aes(x = factor(OverallCond))) + geom_bar()
```

Probably better to write a function. 

```{r}
data_sub %>% ggplot(aes(x = TotalBsmtSF)) + geom_boxplot()
```

```{r}
# Add SalePrice
data_sub %>% ggplot(aes(x = TotalBsmtSF, y = SalePrice)) + geom_point() +
  geom_smooth(method='lm') # Overlay a regression line 
```

This implies that the model is a poor fit 
$$
\mu(SalePrice | TotalBsmtSF) = \beta_0 + \beta_1 TotalBsmtSF
$$

### Separate categorical variable from continuous variable 

```{r}
#rapply(data_sub, class = "numeric", f = levels, how = "list") # Not quite
```

```{r}
#rapply(data_sub, class = "factor", f = levels, how = "list")
```

The list goes on... 

```{r}
data_sub %>% glimpse
```

## Correlation 


## Models 

Review SLR 

### SLR 

```{r}
fit1 <- lm(SalePrice ~ TotalBsmtSF, data = data_sub)
summary(fit1)
```

The model is given as 
$$
\mu(SalePrice | TotalBsmtSF) = \beta_0 + \beta_1 TotalBsmtSF
$$

The fitted model is 
$$
\hat{\mu}(SalePrice | TotalBsmtSF) = \hat{\beta_0} + \hat{\beta_1} TotalBsmtSF
$$
$$
= 1.522e05 + 1.257e01 * TotalBsmtSF
$$

The model is a poor fit (Adjusted R-squared: 0.03806). 

How about model assumption? One of the model assumptions is constant or equal variance, which is violated. Other assumptions include normality, independence, and linearlity. 

```{r}
library(broom)
fit1_df <- augment(fit1)
fit1_df %>% ggplot(aes(x = .fitted, y = .resid)) + geom_point() + 
  geom_hline(yintercept = 0) + 
  labs(title = "Residuals vs Fitted")
```

### MLR 

```{r}
fit2 <- lm(SalePrice ~ TotalBsmtSF + LotArea, data = data_sub)
summary(fit2)
```

The fitted model is
$$
\hat{\mu}(SalePrice | TotalBsmtSF) = \hat{\beta_0} + \hat{\beta_1} TotalBsmtSF + \hat{\beta_2} LotArea 
$$

The fit is till pretty poor. 

```{r}
fit2_df <- augment(fit2)
fit2_df %>% ggplot(aes(x = .fitted, y = .resid)) + geom_point() + 
  geom_hline(yintercept = 0) + 
  labs(title = "Residuals vs Fitted")
```

Fit 3 Add another continuous variable and see if R-squared or Adjusted R-squared changes.

Fit 4 Add another continuous variable.

Fit 5 Add another continuous variable. 

Fit 6 Return to fit1 but add an additional categorical variable. 

```{r}
fit6 <- lm(SalePrice ~ TotalBsmtSF + factor(MSZoning), data = data_sub)
summary(fit6)
```

```{r}
fit6_2 <- lm(SalePrice ~ -1 + TotalBsmtSF + factor(MSZoning), data = data_sub)
summary(fit6_2)
```


First notice that MSZoning has 5 levels 
```{r}
#levels(data_sub$MSZoning) #NULL
# str(data_sub$MSZoning) #chr
# Convert to the right data type 
data_sub$MSZoning <- factor(data_sub$MSZoning) # base R 
levels(data_sub$MSZoning) 
```

```{r}
unique(data_sub$MSZoning)
```

Not quite sure why the default reference group is named C (all). Because R picks it. 

```{r}
levels(data_sub$MSZoning)
```

The model is given as 
$$
\mu(SalePrice | TotalBsmtSF, MSZoning) = \beta_0 + \beta_1 TotalBsmtSF  + \beta_2 MSZoningFV + 
$$
$$
\beta_3 MSZoningRH + \beta_4 MSZoningRL + \beta_5 MSZoningRM, 
$$
where MSZoningFV, MSZoningRH, MSZoningRL, and MSZoningRM are all indicator variables, i.e., for MSZoningFV, then MSZoningFV = 1 if MSZoning = FV, MSZoningFV = 0 otherwise. 

$$
MSZoningFV = 1 \ \ \text{if} \ \ \text{MSZoning = FV}
$$
$$
MSZoningFV = 0 \ \ \text{otherwise}.
$$

So then, for MSZoning = C (all) (the reference group), the regression line is given as 
$$
\mu(SalePrice | TotalBsmtSF, MSZoning = ref) = \beta_0 + \beta_1 TotalBsmtSF 
$$

For MSZoning = FV, the regression line is given as 
$$
\mu(SalePrice | TotalBsmtSF, MSZoning = FV) = \beta_0 + \beta_1 TotalBsmtSF + \beta_2 MSZoningFV + ....
$$
$$
= (\beta_0 + \beta_2) + \beta_1 TotalBsmtSF
$$

For MSZoning = RH, the regression line is given as 
$$
\mu(SalePrice | TotalBsmtSF, MSZoning = RH) = \beta_0 + \beta_1 TotalBsmtSF + \beta_3MSZoningRH + ...
$$
$$
= (\beta_0 + \beta_3) + \beta_1 TotalBsmtSF
$$

For MSZoning = RL, the regression line is given as 
$$
\mu(SalePrice | TotalBsmtSF, MSZoning = RL) = \beta_0 + \beta_1 TotalBsmtSF + \beta_4MSZoningRL
$$
$$
= (\beta_0 + \beta_4) + \beta_1 TotalBsmtSF, 
$$
etc. 

If we were to plot these regression lines altogether, they'll be parallel to one another. They only differ by intercepts. Since the effects are additive, this model is called additive model. 

It is important to know that  

- $\beta_2$ is the estimated mean response (difference) switching from MSZoningFV to the reference group while keeping all else constant, 

- $\beta_3$ is the estimated mean response switching from MSZoningFV to the reference group while keeping all else constant, 
- $\beta_4$ is... MSZoningRH to the reference group while..., 

- $\beta_5$ is... MSZoningRL to the reference group while...

Depends on our research of interest, sometimes we may want to use the relevel() function either to re-level/re-order the group or set a different reference group. When we do, we may end up with a different "re-parametrized" model, which is still a valid model so long as we keep the number of coefficients $\beta$s is right. 

Again back to the model that fits the intercept, TotalBsmtSF and MSZoning, we know that for any model to be a valid model we need a total of 6 $\beta$s. This is because 1 (intercept) + 1 (TotalBsmtSF: continuous) + 4 (MSZoning has 5 levels but 1 of them is the reference group). 

Is fit6 a valid model? 

Fit 7 fit a re-parametrized model of fit6 while setting MSZoning = FV as the reference group. 

```{r}
unique(data_sub$MSZoning)
```

```{r}
data_sub$MSZoning <- relevel(data_sub$MSZoning, ref = "FV")
```

This didn't work because we didn't save it. Now it does. Now FV is the reference group. 
```{r}
levels(data_sub$MSZoning)
```

For fit 7, without fitting the model yet, can you write down the model? 

For fit 7, without fitting the model yet, can you interpret what each $\beta$ mean? 

```{r}
fit7 <- lm(SalePrice ~ TotalBsmtSF + MSZoning, data = data_sub)
summary(fit7)
```

Is fit7 a valid model? 

Referring back to the plot of SalePrice vs MSZoning, sometimes it is better to fit an ANOVA model instead especially if the trend is not clear. The advantage of ANOVA model is that it let us to test the overall effect of MSZoning on SalePrice. 

```{r}
fit7_2 <- lm(SalePrice ~ MSZoning, data = data_sub)
anova(fit7_2)
```

Since p-val is low (Pr(>F) = 1.375e-10 ***), we conclude that there is a significant effect of MSZoning on SalePrice. However, without looking further, we wouldn't know which level of MSZoning has the effect since the null hypothesis Ho corresponding to the MSZoning row is to test $H_o:$ $\alpha_i = 0$ for $i = 1,2,3,4,5$. When we reject the Ho, we can also say that at least one of the $\alpha_i$ differs from $0$. 

Fit 8 Return to fit2 and fit a model with interaction term. Such model is also called non-additive model 

```{r}
fit8 <- lm(SalePrice ~ TotalBsmtSF + LotArea + TotalBsmtSF:LotArea, data = data_sub)
summary(fit8)
```

The p-val associated with TotalBsmtSF:LotArea (Pr(>|t|) = 4.54e-05) is significant, whcih means that there is a significant interactive effect between TotalBsmtSF and LotArea. That is, the effect of TotalBsmtSF on the response variable (SalePrice) depends on/interacts with LotArea, and vice versa. 

None of the model we fit so far is a good fit, but it is a start. 
